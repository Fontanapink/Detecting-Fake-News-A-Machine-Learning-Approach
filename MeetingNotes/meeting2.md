# Dataset we will use

We will use the Kaggle dataset. [Here](https://github.com/Fontanapink/Detecting-Fake-News-A-Machine-Learning-Approach/tree/main/Example-1) is a baseline model you can start tweaking or consider. With the dataset,
- we can use less things from the dataset (removing names of people or agency like Trump or Reuters) to make the dataset more challenging / realistic to analyze.
- We can also use different metrics (other than the raw accuracy) to more accurately reflect model performance.

# This week's main goal: data visualization / exploratory data analysis (EDA) / data preprocessing

Each person brainstorms a feature or selects one feature from [our document "Ideas/concerns/opinions..." item 2](https://docs.google.com/document/d/1DNczb1nMEhkRcQA6TphjL8hI46tRyMtm9uL3yfk-20M/edit#) and does exploratory data analysis with it. For instance, this may be visualizing the word frequency cout, or a word cloud of the vocabulary differences between real vs fake news. 

Let others know which feature you are working on by commenting on the above linked document.

Pedro: https://towardsdatascience.com/fake-news-detector-with-deep-learning-approach-part-i-eda-757f5c052 is a link for some exploratory data analysis ideas too.

For this project to be successful, do especially consider a feature that others have not done before.

# This week's minor goal

If you have time, try to use one or two of the following models to analyze our dataset, suggested by Pedro and Thomas:
- Gaussian processes (Pedro)
- TF-IDF and PCA
- Naive Bayes (Guillermo)
- n-gram
- Word2vec and logistics regression
- RNN/LSTM
- BERT (May require more computational resources...)

# Recurring meeting

We shall meet regularly on Tuesdays at 1:30 PM.
